---
abstract: Long-term records of the flow of water through tidal channels are essential to constrain the budgets of sediments and biogeochemical compounds in salt marshes. Statistical models which relate discharge to water level allow the estimation of such records from more easily obtained records of water stage in the channel. Here we compare four different types of stage-discharge models, each of which captures different characteristics of the stage-discharge relationship. We estimate and validate each of these models on a two-month long time series of stage and discharge obtained with an Acoustic Doppler Current Profiler in a salt marsh channel. We find that the best performance is obtained by models which account for the nonlinear and time-varying nature of the stage-discharge relationship. Good performance can also be obtained from a simplified version of these models which captures nonlinearity and nonstationarity without the complexity of the fully nonlinear or time-varying models.
---

# Introduction

The flow of water into and out of tidal channels carries with it nutrients, sediment and biota thus exerting a strong control on the biology and geomorphology of environments such as mudflats, mangroves and salt marshes [@Morris_2002; @Chmura_2003; @Duarte_2005; @Cai_2011; @Fagherazzi_2013]. Accurately estimating the volumetric flux of water, or discharge, through a channel is a crucial component of estimating the flux of materials transported through these systems. In fact, the flux of an advected material is equal to its concentration multiplied by the discharge. Precise estimates of discharge from water levels are important to quantify the exchange of biogeochemical compounds between marshes and nearby bays [@Carey_2014] and determine the stability of salt marshes from channel sediment fluxes [@Ganju_2013].

The development of rating curves which relate the easily measured water level, or stage, in a stream cross section to the flow through that cross section is routinely carried out in rivers [@Kennedy_1984]. Once a rating curve is calculated, discharge can be instantaneously estimated by measuring water level. In coastal streams influenced by tides, simple models for rating curves (such as power laws) fail because of the bidirectional and nonstationary nature of flow in these environments (Fig. \ref{data}c). Bidirectionality means that, in one tidal cycle, there are two discharges with opposite signs for a given stage. The asymmetry of the tides [@Boon_1975; @Pethick_1980; @Healey_1981; @Fagherazzi_2008] means these discharges are not simply negatives of each other, with a _hysteresis_ between ebb and flood. Nonstationarity in tidal channel flow means that a single water level corresponds to many different discharges (Fig. \ref{data}c) over the course of a stage-discharge record. Nonstationarity comes from storm tides and from lower-frequency harmonics of the tide such as the spring-neap cycle, resulting in different discharges for the same water level. This multiplicity of discharge at a single stage means that we cannot estimate a single rating curve in which discharge at a point in time is a function of stage at that instant.

![a) Velocities in the horizontal plane recorded by the Acoustic Doppler Current Profiler. The dominant direction of variability corresponds to the along-channel velocities, and that direction is extracted using principal components (the red arrows). b) The true discharge obtained with a handheld flow meter plotted against the index discharge derived from the ADCP. The red line represents the linear model $Q_{MM} = 0.4997Q_{ADCP} -0.0552$ used to calibrate the index discharge to the true discharge. c) Stage and discharge time series. The red dashed line in the stage time series represents the elevation of the channel bank. The spring-neap tidal cycle over the course of the month results in nonstationarity in the discharge time series. d) An example stage-discharge relationship from a one-month ADCP record in Sweeney Creek, Rowley, MA. Note the bidirectionality and hysteresis in ebb and flood.\label{data}](figures/discharge/data.pdf)

The goal of this manuscript is to develop robust and interpretable models that predict discharge from stage in salt marsh channels. Given a record of stage and one of discharge, we aim to find some function of the stage which will return discharge so that, in the future, a record of stage from an independent water level logger can be used to estimate discharge. There are any number of approaches drawn from the statistical and machine learning disciplines, such as neural networks and support vector machines, which can perform fairly well at this problem [@Tawfik_1997; @Sudheer_2003; @Sahoo_2006; @Ghorbani_2016]. However, demanding interpretability from any useful model of stage and discharge, constrains the tools which we can use. By interpretability, we mean that the structure of the stage-discharge model and its parameters are based in real properties of the marsh we are studying. If we possess an interpretable model, we can invert a model fit to stage-discharge data from a creek to learn about the structure of flow through the salt marsh, such as its channel topology, storage properties, and interactions between surface water and groundwater.

Here we examine a suite of models for estimating discharge from stage measurements. We explore the structure of each of these models and their relation to our physical understanding of flow in tidal systems and discuss the challenges to estimating the parameters of each of these models from stage and discharge data. We present a case study using stage-discharge records from a salt marsh creek along the Rowley River, Massachusetts, USA, to compare the performance of each of these methods. We conclude by discussing the advantages of each model and we make some recommendations for stage-discharge modelling in tidal creeks.

# Procedures

## Discharge measurements

We acquired a data set associating discharge with creek stage in August and September 2015 in a salt marsh creek (Sweeney Creek) along the Rowley River, MA. A Nortek Aquadopp acoustic Doppler current profiler (ADCP) operating at 2.0 MHz was programmed to record velocities in 20 cm bins at 10 minute intervals. The blanking distance of the ADCP was set to 10 cm, so that the center of the first bin is 20 cm above the ADCP. The ADCP parameters are given for reference in Table \ref{ADCPparams}. We installed the ADCP looking upward in the creek thalweg.

The velocity data retrieved from the ADCP come in the form of three $B\times N$ matrices where $B$ is the number of bins and $N$ is the number of points recorded in time. Each of the three matrices represents velocity in one of three directions (east, north and up, ENU). In addition, the water pressure recorded by the ADCP is retrieved. This pressure is converted to a height of water above the ADCP by dividing by the specific weight of water. The velocity data are filtered to remove velocities recorded in bins above the water level and then the valid velocities are averaged to provide a trivariate time series of average velocity above the ADCP in each of the three directions.

Because the velocity variations in the creek channels which we examine are driven entirely by tides, the variability in velocity is dominated by the along-channel component of velocity. This motivates the use of principal components analysis to rotate the trivariate ENU velocity time series into another trivariate time series with components in the along-channel, across-channel and vertical directions. The first principal component (that with the largest eigenvalue) represents the along-channel velocity, the second, the across-channel, and the third, the vertical (Fig. \ref{data}a). The along-channel velocity is the index velocity in the cross section, and it is this component that we use to calculate the discharge.

We use the stage measurements from a pressure transducer in the ADCP along with a channel cross section measured by an RTK-GPS to calculate the flooded cross-sectional area. The index discharge is calculated by multiplying this area by the index velocity. This overestimates the true discharge through the channel because the velocity in the center of the channel tends to be higher than the velocity near the creek banks. Calibration of the index discharge to the true discharge is essential for any consistent estimate of material flux in the channel [@Ruhl_2005]. We calibrate the index discharge to a true discharge with measurements taken with a handheld flow meter (Marsh-McBirney Flo-Mate 2000). We fit a linear regression from the index discharge to the true discharge [@Ruhl_2005] and then apply this regression model to the entire index discharge time series to obtain a true discharge time series. The final output of these discharge measurements are two time series: one of true discharge and one of stage. We deployed the ADCP for two thirty-day deployments.

## Modelling of the discharge

We examine four different classes of model: an instantaneous, geometric model of flow proposed Boon [-@Boon_1975], a linear, time-invariant model inspired by the unit hydrograph formulation of flow in rivers [the TIGER model presented in @Fagherazzi_2008], a nonlinear, time-invariant model based on the Volterra series [@Rugh_1981], and a new linear, time-variant model inspired by the recent interest in time-variable travel time distributions [@Fagherazzi_2008; @Botter_2010; @Harman_2015; @Beven_2015]. Below we briefly describe the models we estimate on our stage-discharge time series. More detail on each model and on the procedures used to estimate the parameters of these models can be found in the supplemental information.

Throughout, we use the notation $Q(t)$ to represent the time-varying discharge in a cross section and $h(t)$ the time-varying stage in that cross section, $\{Q_i\}_{i=0}^{N-1}$ and $\{h_i\}_{i=0}^{N-1}$ are the discrete stage-discharge time series of length $N$ taken at a sampling interval of $\Delta t$ (i.e. $Q_i = Q(i\Delta t)$ and likewise for the stage).

### The Boon model

Boon [-@Boon_1975] proposed a stage-discharge model as follows

\begin{equation}
Q(t) = A(h) \frac{dh}{dt}
\end{equation}

where $A(h)$ represents the hypsometric curve, the distribution of area within the salt marsh as a function of height. This model can be derived from the continuity of mass under the assumption that water surface slopes are negligible throughout the marsh. We assume here that we do not possess a description of the hypsometric curve as might be derived from LiDAR or aerial photography surveys. Instead, we estimate a representation of the hypsometric curve from the stage-discharge data. Specifically, we use a power law form for the hypsometric curve, $A(h) = \alpha h^{\beta}$. We approximate $dh/dt$ by the backward difference operator: $\left.dh/dt\right|_{t=i\Delta t} \approx (h_i - h_{i-1})/\Delta t$. That is, we obtain a nonlinear system of equations in the parameters $\alpha$ and $\beta$ of the form

\begin{equation}
Q_i = \alpha h_i^\beta (h_i-h_{i-1})
\end{equation}

for $i \in \{2,...,n\}$ which we solve for the optimal values of $\alpha$ and $\beta$ using nonlinear least squares with the Nelder-Mead method [@Kelley_1999].

Extensions of Boon's model have been studied by Pethick [-@Pethick_1980], who proposed theoretical forms of $A(h)$ based on simple models of channel geometry which are encompassed by the power law model we use here.

### Linear, time-invariant models

The assumption in the Boon model that water surface slopes are negligible has been pointed out as unrealistic in many situations [@Healey_1981; @Fagherazzi_2008], and the model requires an asymmetric tide to generate asymmetric discharges [@Pethick_1980]. More fundamentally, the Boon model assumes that the tide propagates instantaneously into the marsh. Fagherazzi et al. [-@Fagherazzi_2008] put forward a model based on the instantaneous unit hydrograph developed for river runoff which relaxes this assumption, assuming that the tidal propagation can be described by a travel time distribution $p(t)$ which determines how much of the flow at time $t$ is due to the increase in stage at time $t=0$. The tidal discharge is obtained by convolving this travel time distribution with the Boon model.

\begin{equation}
Q(t) = \int_{-\infty}^{t} A(h) \left.\frac{dh}{dt}\right|_{t=\tau} p_h(t-\tau)\ d\tau
\end{equation}

Because of the dependence of the hypsometric curve $A(h)$ and the travel time distribution on water stage, this formulation is naturally time-variant. We first consider a time-invariant version of this model ($p_h(t) = p(t)$ for all $t>0$) which is both very simple to estimate and able to draw on the rich literature on system identification in linear, time-invariant systems

\begin{equation}
Q(t) = \int_{-\infty}^t \left.\frac{dh}{dt}\right|_{t=\tau} \beta(t-\tau)\ d\tau
\end{equation}

where we note that we have also incorporated the hypsometric curve into the time-invariant travel time distribution, averaging out its temporal variation to preserve the time-invariance of the model. In other words, we do not estimate a hypsometric curve explicitly in this or any of our later models. This integral equation can be discretized at our sampling frequency, which results in an overdetermined system of linear equations in the parameters, $\mathbf{\beta} = \{\beta_i\}_{i=0}^{M-1}$.

\begin{equation}\label{LTI}
Q_n = \sum_{i=0}^{M-1} \beta_i \left.\frac{dh}{dt}\right|_{t = (n-i)\Delta t}
\end{equation}

Since we ultimately approximate the derivative by a backward difference, the linear model is equivalent to one with $dh/dt$ replaced by $h$ in Eq. \ref{LTI} and the backward difference incorporated into the kernel coefficients, $\{\beta_i\}_{i=0}^{M-1}$.

$M$ is the system order which determines how far back in time the discharge depends on stage. The system order is a hyperparameter of the problem which needs to be selected before estimating the model parameters $\mathbf{\beta}$. We perform hyperparameter optimization for this and all models using cross-validation, explained below.

### Nonlinear, time-invariant models

Frictional interactions between water, the banks of the channel and the marsh surface introduce nonlinearities into the continuity formulation [@Speer_1985]. Heterodyning of the stage signal by the nonlinear friction terms introduces higher frequency harmonics of the tide into the discharge, which helps explain the tidal discharge asymmetry [@Speer_1985; @Blanton_2002]. A linear model such as the system above is unable to account for this behavior: it cannot generate frequencies in the output signal which are not present in the input signal; it can only attenuate or amplify the strength of the signal at certain frequencies. We therefore investigate a nonlinear (but still time-invariant) model which is capable of generating these harmonics.

The canonical nonlinear equivalent to the linear, time-invariant system is the Volterra series, also seen in its orthogonalized version, the Wiener series. The Volterra series bears the same relationship to a linear, time-invariant system as a Taylor series does to the evaluation of a function at a point: it can be thought of as a Taylor series with memory. The Volterra series expands the system as a series of integrals of products of the stage signal at different lags

\begin{equation}
Q(t) = \sum_{k=0}^K \int_{-\infty}^t \cdots \int_{-\infty}^t f_k(t-\tau_1,. . .,t-\tau_k) \prod_{j=1}^k h(\tau_j)\ d\tau_j
\end{equation}

so that the first few terms look like

\begin{equation}
Q(t) = f_0 + \int_{-\infty}^t f_1(t-\tau_1) h(\tau_1)\ d\tau_1 + \int_{-\infty}^t\int_{-\infty}^t f_2(t-\tau_1,t-\tau_2) h(\tau_1)h(\tau_2)\ d\tau_1 d\tau_2 + \cdots
\end{equation}

Note that the first convolution in this series is simply the linear time-invariant system, and the n-th term in the series involve n-th degree monomials of the stage at n different times in the past. We can likewise discretize the Volterra series, giving us a set of nonlinear equations in the coefficients (the discrete versions of the functions $f_k$). To estimate the coefficients effectively, we exploit the duality between the Volterra series and polynomial kernel regression [@Franz_2006].

### Linear time-variant models

Both the linear, time-invariant model and the Volterra series model are unable to capture the activation of different flow paths, such as when the water overtops channel banks and moves as sheet flow over the marsh platform. By estimating a single travel time distribution for the entire stage-discharge record, we tend to underestimate the high magnitude discharges just before and after the high slack water and to overestimate the discharge at relatively low flows which are dominated by residual drainage from the low-order creeks and ditches in the system and from seepage out of channel banks. Thus the TIGER model of Fagherazzi et al. [-@Fagherazzi_2008] and similar models developed for river basins [@Botter_2010; @Harman_2015] explicitly account for time-varying travel time distributions. Estimating these travel time distributions is not a well-posed problem because one needs to estimate both the distribution itself and the dynamics of the distribution as it changes change continuously in time.

We therefore have to approximate the dynamics of travel time distributions so that they can be estimated with the finite amount of data that we have. We assume that there are a finite number of states which the flow can be in. We partition the time series into these states and estimate a linear, time-invariant travel time distribution for each state with only those data points representing these states. To predict discharge from a new stage trajectory, we assign the new trajectory to the appropriate state and use the linear model associated with that state to estimate the discharge.

We need to devise a principled way to partition the training data set into states and to assign a new, unobserved stage trajectory to a state. Here, for simplicity, we use an unsupervised clustering method [k-means; @Xu_2009] to partition the $M$-dimensional training stage trajectories into $k$ clusters such that each trajectory belongs to the cluster with the closest mean in the Euclidean distance. Upon receiving a new trajectory, we compute the distance from the new trajectory to each of the $k$ cluster centers and assign it to the cluster with the smallest distance.

This unsupervised method uses only the information in the stage trajectories to form the clusters. It does not take into account the predictive performance of each cluster; this is not necessarily the optimal clustering for discharge estimation. One could, in principle, construct a clustering to optimize the estimation performance, but one would then need to model separately the process which assigns new stage trajectories to these clusters using a supervised classification technique. In practice, the unsupervised clustering performs well without this additional complication.

### Regularization

The individual stage measurements at each ten minute interval are highly correlated with each other, so that each stage data point does not provide independent information for the discharge prediction. This is the collinearity problem familiar to users of any multiple regression [@Hocking_1976; @Wold_1984]. When performing a straightforward regression with this collinear data, we will tend to overfit our model to the training data, reducing its ability to generalize to new data. We will also obtain unphysical estimates of the parameters that oscillate rapidly and are sensitive to noise. Regularization trades off fitting the training data set and constraining the parameters in some way. Variable selection by a stepwise procedure or model selection with the Akaike information criterion [@Burnham_2002] is one form of regularization. Here, we use Tikhonov regularization (also called ridge regression) which adds a penalty term to the least-squares objective function

\begin{equation}
\hat{\beta} = \underset{\beta}{\operatorname{arg\,min}} \sum_{i=1}^N (Q_i - H_i\beta)^2 + \|\Gamma\beta\|^2
\end{equation}

where $\Gamma$ is some positive semi-definite matrix. The penalty term enforces some constraints on the structure of the coefficients, $\beta$, constraints chosen by the regularizing matrix $\Gamma$. For $\Gamma$ a multiple of the identity matrix, $\Gamma=\lambda I$, we obtain the common $L_2$ regularization which penalizes solutions with higher Euclidean norms, leading to smooth parameter estimates with the degree of smoothness controlled by the hyperparameter $\lambda$. Other choices of $\Gamma$ impose different constraints on the system which may enhance the interpretability of the model. For example, stable spline kernels [@Pillonetto_2010] enforce stability of the linear, time-invariant system, leading to an appropriately decaying impulse response, while in kernel regression methods such as that used to implement the Volterra series model, the matrix $\Gamma$ corresponds to the measurement error covariance. However, we use $L_2$ regularization in our assessment below, as it offers reasonable performance without much additional complexity.

### Cross-validation

To estimate the hyperparameters of each model, such as the system order or the regularization parameter, we use a cross-validation approach. We divide our training data set evenly into two blocks, and, for each value of each hyperparameter on a grid, we estimate the model using the data from the first block. We apply the estimated model to the second half of the training data set and measure the mean squared error between the estimated discharge and the observed discharge in that block. We choose the values of the hyperparameters which minimize this prediction mean squared error and reestimate the model on the entire training data set using these optimal hyperparameters before applying it to any further stage records from the same creek.

### Discharge estimation with a fitted model

To apply these models to develop a stage-discharge relationship for a particular channel, one must first collect a training data set with an ADCP and fit the model as described above. From then on, discharge can be estimated with only an independent water level logger instrumenting the channel. One records water level in the same cross section at the same sampling rate as the training data in the same cross section. Different cross sections will exhibit different stage-discharge relationships, and a model estimated on one cross-section is not valid at another cross section even in the same channel. The sampling rate must be identical because the each of the parameters in all of the models take the form of a coefficient that is applied to stage a certain amount of time in the past. To estimate discharge at the present time, one collects the stage time series from the present stretching back into the past a certain amount of time. We call this short record a "stage trajectory." In our measurements, at time steps of 10 minutes each, a 25 hour long stage trajectory is a vector of length 150. Each model takes a stage trajectory and applies some transformation to it -- a linear combination of the stages in the linear, time-invariant model, for instance -- and returns an estimate of discharge. If estimates of uncertainty are required for the estimated discharge value, bootstrap methods adapted for time series [@Buhlmann_2002] can be easily applied to each of the models, though we will not specifically address methods for uncertainty quantification here.

# Assessment

To compare the performance of each of these models, we estimate each model on our ADCP stage-discharge records from the Rowley marshes. We follow the cross-validation procedure outlined above to estimate the parameters for each model on the first of the two stage-discharge records and apply the model to the second ADCP record. We examine, in turn, the parameters estimated for each model, the estimation performance of each model on the second stage-discharge record, the behavior of the residuals, and the impact that regularization has on both the estimated parameters and the estimation performance.

## Model structure

Each of the four classes of model uses a slightly different type of parameter set, and we show each of the resulting parameters in Fig. \ref{params}. The Boon model produces an estimated hypsometric curve in a power law form (Fig. \ref{params}a). The linear time-invariant model produces a single impulse response, representing the contribution of stage in the past to flow in the present (Fig. \ref{params}b). The Volterra series model generates a set of multidimensional impulse response functions. For simplicity, we show just the first order Volterra operator, which is just a linear, time-invariant impulse response, and the second order Volterra operator, which is a two-dimensional set of coefficients (Fig. \ref{params}c). The k-means model produces $k$ impulse responses, one for each of the clusters, and also assigns each point in the time series to one of these clusters (Fig. \ref{params}d).

![a) The hypsometric curve estimated in the Boon model. b) The impulse response estimated in the linear, time-invariant model. c) The first-order Volterra kernel is equivalent to a linear, time-invariant impulse response (top). The second-order kernel is a two-dimensional analogue of the impulse response. The distance along the x- and y-axes are the lags backwards in time for each of the directions of the impulse response. The color is the amplitude of the impulse response. d) The k-means model estimates $k$ impulse responses (left). Each impulse response is used to estimate from the correspondingly colored point in the stage time series (right) \label{params}](figures/discharge/ir.pdf)

The ideal system order in the linear models and the Volterra series describes how much memory is needed to estimate discharge effectively. Using cross-validation to select the system order ensures that we do not choose an order too large, in which case the model would overfit the data and have poor prediction performance on the validation data set. We find that, for the linear models, the optimal system order corresponds to approximately 25 hours or two full tidal cycles.

For the Volterra series, however, fewer lagged measurements of stage are required to predict the discharge, with an optimal system order around three hours. In estimating the Volterra series by a polynomial kernel regression, we exchange memory for degrees of nonlinearity as the number of parameters for each order of the Volterra operator scales as $N^m$ for a system order of $N$ and a Volterra operator order of $m$. Given our finite data set, we will be able to estimate only a finite total number of these parameters, so using a higher system order -- a longer memory -- forces the order of the Volterra series down. And indeed the optimal Volterra order for a three-hour system order is 5, corresponding to polynomials up to quintics, while that for a 25-hour system is 3, corresponding to cubic polynomials.

The k-means model uses an unsupervised method to determine which cluster a new stage trajectory belongs to, so that the clustering is determined entirely by the shape of the stage signal. Two given stage trajectories will be closest in the Euclidean metric when they are perfectly in phase and farthest apart when they are perfectly out of phase, so any unsupervised clustering method using the Euclidean metric will naturally cluster based on the phase of the tidal signal, as we find in Fig. \ref{params}d. For a system order of 25 hours, the optimal number of clusters is around four, corresponding roughly to a low flood tide, a high flood tide, a high ebb tide and a low ebb tide.

We have found in practice, that the k-means clustering approach can be easily replaced by an ad hoc procedure which extracts the four clusters mentioned above simply using local information on the stage and stage derivative, making this approximation useful for real-time discharge estimation. The distinction between flood and ebb tides can be found where the time derivative of stage (approximated with the backward difference) changes sign. It is positive on the flood tides and negative on the ebb tides. The distinction between high and low stages can be based on a threshold, which we choose by cross-validation. The threshold selected by cross-validation for the Sweeney Creek stage-discharge time series is approximately 1.4 m which is just below the top of the right bank (Fig. \ref{data}b). This threshold indicates a fundamental difference between flow when the water level is above the bank, flooding the vegetated marsh surface and flow when the water is below the bank.

## Model performance

For each of the models (Boon, LTI, Volterra, k-means), we use cross validation to estimate the model with good choices for hyperparameters. We reestimate the model on the entire first time series using the good hyperparameters and apply each estimated model to our second stage-discharge time series and plot the modeled discharge values against the observed values in Fig. \ref{performance}. The ideal modelled discharge values would lie on the red one-to-one line in Fig. \ref{performance}. We report the Nash-Sutcliffe efficiency and the mean squared error of each model in Table \ref{results} to compare the prediction performance of the four models.

![The modeled discharge plotted against the observed discharge. The red line in each plot is the one-to-one line. \label{performance}](figures/discharge/performance.pdf)

The Volterra series model is the best performing (has the highest Nash-Sutcliffe efficiency and lowest mean squared error), followed by the k-means model, the Boon model and the linear, time-invariant model, a ranking which is supported by the visual representation of model fit, Fig. \ref{performance}. Each of the four models tends to underestimate the high discharges and to overestimate the low discharges. At high magnitudes of the discharge, both positive and negative, points in Fig. \ref{performance} tend to lie on the side of the one-to-one line closer to the x-axis, while at smaller discharges, they tend to lie on the side further from the x-axis. This effect is more pronounced in the more poorly performing models (Boon and linear, time-invariant). 

## Residual structure

If our model completely captured the discharge-generating behavior of our salt marsh system, we would expect the residuals to be roughly independently distributed, in other words the error in the model comes not from systematically misestimating discharge at certain points of the time series but from random fluctuations in the velocity or from instrument noise. In addition to examining the fit of each model, we therefore also want to examine the structure present in the residuals. The predictive capability of two models being equal, we prefer the one with the least correlation in the residuals, or, in the frequency domain, the model with the flattest spectrum. We plot the residual time series and power spectra for each of the four models in Fig. \ref{residuals}. While we observe some structure in the residuals, it is hard to determine visually which of the models whitens the residuals the best. We would like a quantitative measure of the residual structure. The Ljung-Box test [@Ljung_1978] provides a statistical test of the the autocorrelation of the residual time series, but as we expect, the test rejects the null hypothesis of no autocorrelation for all of the models here, so the test itself does not adequately discriminate between the models. Instead, we use the spectral flatness (the ratio of the geometric mean of the power spectrum to the arithmetic mean) to measure how close to a white spectrum the residuals are. Flatness ranges from zero, at a signal with a single frequency, to one, at a purely white spectrum, so higher values of the spectral flatness indicate a better-specified model.

The estimated flatness of the residuals range from 0.022 for the linear, time-invariant model to 0.27 for the Volterra series model (Table \ref{results}). These values suggest that the Volterra series model is the best specified model of the four.

![The residual time series for each of the four classes of models: a) Boon, c) Linear, time-invariant, e) Volterra series g) k-means. The power spectrum of the residual time series for each of the four models b) Boon, d) Linear time-invariant, f) Volterra series, b) k-means. \label{residuals}](figures/discharge/residuals.pdf)

## Effect of regularization

The unregularized linear, time-invariant impulse response is compared to that estimated with regularization in Fig. \ref{regularized}. We see that the effect of $L_2$ regularization is to smooth out the estimated coefficients. The main features of the response such as the high peak just after 100 lags (approximately 17 hours) are preserved in the regularized impulse response, but the finer scale oscillations are damped by the regularization. As the regularization parameter $\lambda$ increases, lower and lower frequency oscillations are filtered out, and the resulting impulse response is smoother. Regularization improves the predictive ability of the linear, time-invariant model very slightly as measured by a larger out-of-sample Nash-Sutcliffe efficiency (from 0.40 to 0.645) and a smaller mean squared error (from 0.976 to 0.962).

![a) The unregularized impulse response for the linear, time-invariant model. b) The regularized impulse response \label{regularized}](figures/discharge/regularization.pdf)

The impact of regularization is much greater on the Volterra series model. The unregularized Volterra series parameters are a set of coefficients each corresponding to one of the data points in the training data set. The estimation procedure, as a result, is extremely sensitive to noise in the data -- the Gram matrix of the polynomial kernel is ill-conditioned -- and regularized is necessary to achieve any predictive ability with the model. When the fifth-order Volterra series model with 19 lags, the optimal model shown above, is estimated with no regularization ($\lambda=0$), the model is flatly unable to predict the discharge. The Nash-Sutcliffe efficiency is $-1\times10^4$ (note that negative Nash-Sutcliffe efficiencies correspond to models which predict the discharge worse than a constant model) while the mean squared error is $1\times10^5$ (the respective values for the regularized model are 0.980 and 0.212). Also notable is the stark increase in the variance of the parameters, from $6\times10^{-11}$ to $2\times10^{15}$, and the corresponding inflated discharges, reaching as high as $2000\ \mathrm{m^3\cdot{}s^{-1}}$. For such a high-dimensional regression problem, regularization is absolutely essential. With regularization, however, the Volterra series performs the best of the four models examined here.

# Discussion

## Physical realism and stage-discharge models

The physical realism of each model roughly corresponds to its success in estimating the discharge. The Boon and linear, time-invariant models both perform fairly poorly in all of the measures examined (Table \ref{results}). The Boon model is derived from a continuity law and is both nonlinear and nonstationary because of its dependence on the hypsometric curve. However, it has long been recognized as incapable of matching the asymmetry and hysteresis between flood and ebb tides because of its lack of memory. Only the slight asymmetry of the stage on the ebb and flood tides enables a discharge asymmetry. The linear, time-invariant model can generate asymmetry because it estimates discharge from the history of the stage over the course of two full tidal cycles. It is therefore aware of whether it is on a flood or an ebb tide and whether it is the higher or lower high tide of the day. The linearity and, more importantly, the stationarity of this model are nonphysical, and this lack of physical realism shows up in the performance of the model. The linear, time-invariant model systematically underpredicts very high discharges and overpredicts the low discharges because a single linear model is trained on the entire data set. It essentially aims to interpolate between the high and the low discharges which causes poor predictive performance on both, the worst performance of the four models.

The k-means model attempts to overcome this unphysical assumption of stationarity by estimating several different models and switching between the models throughout the tidal cycle. In doing so, it accounts somewhat for the nonlinearity problem as well. It segments the high-dimensional space of the stage trajectories into $k$ Voronoi cells and constructs a piecewise linear approximation to the nonlinear function which predicts discharge from stage trajectories. The piecewise linear approximation should converge to the true nonlinear function as the number of partitions increases, and the number of partitions is here limited mostly by the amount of data available for training. As a result of this ability, it performs significantly better than the first two models. The Volterra series, while time-invariant and, like the linear, time-invariant model, unable to account for nonstationarity, captures naturally the nonlinearity present in the shallow water equations, which ultimately govern the system. The spectral flatness results show that this model is the best specified of the four. The Volterra series model is a parametric nonlinear system, but the duality between the Volterra series and polynomial kernel regression means we estimate the series with the latter, a nonparametric estimator of the system response. Because the kernel regression is nonparametric, it is not restricted by our misspecification and, with infinite training data and appropriate regularization to reduce the effect of noise, we should be able to converge on as close an approximation to the true system as is possible with a time-invariant model.

$L_2$ regularization is straightforward to implement, and for the discharge estimation problem, it is sufficient for estimating effective parameters. However, it does not necessarily lead to straightforwardly interpretable model coefficients. The impulse response of the linear, time-invariant model, for example, is a combination of the travel-time distribution, the hypsometric curve and the action of the time derivative, all of which are approximations because of the assumptions of linearity and time-invariance. A more sophisticated regularization scheme would take into account knowledge of the behavior of these parameters -- such as the non-negativity and decaying tail of the travel-time distribution. If formulated carefully, these prior assumptions can be easily incorporated into the present regularization scheme by choosing an appropriate Tikhonov matrix (as in stable spline kernels [@Pillonetto_2010]). More complex prior assumptions such as sparsity of the impulse response coefficients can not be handled with the quadratic penalty term of Tikhonov regularization, but other frameworks exist for these alternative forms of regularization [@Tibshirani_1996; @Zou_2005; @Aravkin_2013] and in a Bayesian formulation of the estimation problem, characterizing our physical assumptions on the models by an arbitrary prior distribution is a type of regularization.

## Limitations of these models

We have tested our models on stage-discharge records from a channel in a macrotidal salt marsh where the channel flow is almost entirely driven by regular tidal forcing. The models almost certainly do not work as well in environments with multiple drivers of flow such as microtidal channels with strong effects of wind on flow, tidally influenced streams with significant upland freshwater inputs, or loops in a channel network where the inputs and outputs do not flow through the same cross section. Future work will quantify which properties of our suite of models remain useful and what additional data might be necessary to extend this modeling framework to these other environments.

## Low flows and missing data

When the stage in the creek is below the first cell of the ADCP profile, no valid velocities are recorded by the instrument. While the velocities at these stages can be fast, the flooded cross-sectional area of the channel is very small, so the true discharges are also small. We fill these missing discharges with zeros, and we estimate all of the models on these zero-filled discharge time series. This imputation is likely to bias our discharge estimates [@Little_2002], and it certainly prevents us from consistently estimating the discharge during these low-flow periods. Volumes exchanged during these periods are small relative to the entire tidal prism, so the imputation with zeros has little impact on the estimated water balance of the marsh. If one is not particularly interested in the exact discharge during these periods, the Boon, Volterra series and k-means model are all able to estimate zero discharges during these periods. These low flows during ebb tides, however, represent slow drainage out of the marsh and creek system and so have the potential to transport significant amounts of nutrients from the marsh [@Gardner_1975; @Fagherazzi_2013]. If it is important to capture these effects or to quantify the uncertainty which results from imputation, more sophisticated modeling of the discharge at low stages is possible [@Hopke_2001].

# Comments and recommendations

## A simplified method to compute tidal discharges from water levels

Based on the results presented herein, we suggest the following simplified method to estimate discharge in tidal channels from water stage using the threshold-based approximation to the k-means model. Choose a threshold stage which corresponds to the elevation of the bank. If the left and right banks are asymmetric or there are multiple steps up to the marsh platform, choose the lowest bank elevation. Segment the time series into four groups: flood tide below the threshold, flood tide above the threshold, ebb tide below the threshold and ebb tide above the threshold. The flood/ebb distinction can be made quantitatively by taking differences between the current stage and the stage at the previous time step. These differences will be positive on the flood tide and negative on the ebb tide.

For each of the four groups of data, form a design matrix where each row represents a data point and each column contains the stage data from the previous time steps. That is, for row $i$, the first column contains the stage at time step $i$, $h_i$, the second column contains $h_{i-1}$, the third column $h_{i-2}$ and so on. The number of columns, $M$, should cover two whole tides. At the 10 minute sampling interval of the time series presented here, this is approximately $M = 150$ time steps, resulting in a design matrix with 150 columns. If the time series is at a different sampling interval, change the width of the design matrix accordingly.

One should now have a design matrix for each of the four time series segments $\mathbf{H_1}$, $\mathbf{H_2}$, $\mathbf{H_3}$ and $\mathbf{H_4}$, and four vectors of discharge values $\mathbf{Q_1}$, $\mathbf{Q_2}$, $\mathbf{Q_3}$ and $\mathbf{Q_4}$ each of which contains the corresponding discharge values for each of the data points. The coefficients of the model are the four vectors $\beta_i = (\mathbf{H_i}^T\mathbf{H_i})^{-1}\mathbf{H_i}^T\mathbf{Q_i}$ which can be obtained with standard routines for linear regression. Once the four vectors of coefficients are obtained, prediction of discharge at a new point proceeds by first deciding to which of the four groups (high flood, low flood, high ebb, low ebb) the water stage belongs. Each of the previous $M$ time steps of the stage is then multiplied by each of the $M$ model coefficients of the corresponding group and added together to provide an estimate of discharge.

## Model recommendations

The complexity of estimating each of these models tracks closely their performance. The linear, time-invariant model is a straightforward linear regression, but it performs the worst (as measured by any of our error measures presented in Table \ref{results}). The Boon model (as formulated here) requires a nonlinear least squares algorithm but does significantly better. The k-means model has a mean squared error half that of the Boon model, but requires some clustering either through k-means or the simplified threshold model presented above. The Volterra model performs the best of all four models but requires a computationally-intensive kernel regression. Choosing between the models is an exercise in trading off complexity for predictive ability and requires a rigorously defined selection criterion adapted to the particular application. We have used the mean squared error, Nash-Sutcliffe efficiency and spectral flatness of residuals to argue that the cubic Volterra series model with 25 hours of lagged stage observations performs the best of the four models. However, each of these measures simply reflects the discrepancy between modeled and observed instantaneous discharges which may not be appropriate for all applications. One could envision the integrated volume of water over a tide being more important than the instantaneous discharge, in which case it might be worth selecting model which slightly misestimates the discharge to get a more accurate estimate of the tidal prism. They also do not take into account the complexity of each model.

To help quantify the tradeoff between complexity and performance for applications, we have calculated the mean absolute percent error for each model as a function of stage (Fig. \ref{mapes}). We bin the stage into 50 cm bins and calculate the mean of the absolute value of the percent error between the modeled and estimated discharge within each bin. This gives some estimate of how far off one might expect to be when using each model to predict discharge over a certain range of stages. The general pattern follows our conclusions from the other measures of the model error with the Volterra series model performing the best, followed by k-means, Boon and the linear, time-invariant model. The Volterra series percent error is around 10-15% at all stages, while the k-means percent error ranges from around 20-30%. While the Boon model has a percent error around 50% at high and low stages, it is within one percent at stages just above the bankfull stage for our channel. If one is interested in estimating only the bankfull discharge in a channel, the Boon model performs just as well as the significantly more complex k-means model.

![Mean absolute percent error for each of the four models as a function of stage. \label{mapes}](figures/discharge/mapes.pdf)

The k-means model, and especially the threshold version represents, we believe, the best model for applications which need to estimate discharge from long-term records of stage such as biogeochemical and ecological investigations. It offers good estimation performance throughout a long time series, because its estimation complexity resides in the selection of clusters, which, as we have shown, can be well-approximated with a heuristic, and because of the appealing interpretation of the clusters in terms of flow regimes.

\newpage{}

# Acknowledgements

This research was supported by the National Science Foundation (awards OCE1354251, OCE1354494, and OCE1238212). Data are publicly available through the Long Term Ecological Research (LTER) Network Data Portal at http://portal.lternet.edu. We would like to thank Neil Ganju for helpful comments on a draft of this manuscript.

\newpage{}

# Tables

Parameter          Value
------------------ -------
Acoustic frequency 2.0 MHz
Blanking distance  10 cm
Cell size          20 cm
Sampling interval  10 min

Table: ADCP parameters \label{ADCPparams}

\newpage{}

Model                  Mean squared error Nash-Sutcliffe efficiency Spectral flatness
---------------------- ------------------ ------------------------- -----------------
Boon                   0.483              0.816                     0.041
Linear, time-invariant 0.962              0.645                     0.022
Volterra series        0.052              0.980                     0.272
k-means                0.245              0.910                     0.257

Table: Performance of the models \label{results}

\newpage{}

# References
